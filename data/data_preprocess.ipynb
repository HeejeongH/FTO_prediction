{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c625dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from molecular_descriptor import *\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2831bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_canonical_smiles(smiles):\n",
    "    if pd.isna(smiles):\n",
    "        return None\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        return Chem.MolToSmiles(mol, canonical=True)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def smiles_to_MD_FP(raw_data, ignore3d):\n",
    "    smiles_list = raw_data['canonical_SMILES'].tolist()\n",
    "    print(\"총 분자 수:\", len(smiles_list))\n",
    "\n",
    "    # MD\n",
    "    desc_df = calc_descriptors(smiles_list, leave_cores=4, ignore3D=ignore3d)\n",
    "    if 'canonical_SMILES' not in desc_df.columns:\n",
    "        desc_df.insert(0, 'canonical_SMILES', smiles_list)\n",
    "    dataset = raw_data.merge(desc_df, on='canonical_SMILES', how='left')\n",
    "\n",
    "    compound_info = dataset.iloc[:, :4]\n",
    "    descriptor_data = dataset.iloc[:, 4:]\n",
    "    print(f\"정제 전 데이터 shape: {dataset.shape}\")\n",
    "\n",
    "    # MD 전처리\n",
    "    ## 결측치 제거\n",
    "    descriptor_data_cleaned, _ = remove_invalid_descriptors(descriptor_data)\n",
    "    print(f\"결측 제거 후 descriptor shape: {descriptor_data_cleaned.shape}\")\n",
    "\n",
    "    ## 분산이 낮은 descriptor 제거\n",
    "    descriptor_data_after_var, _ = remove_low_variance_descriptors(descriptor_data_cleaned, threshold=1e-6)\n",
    "    print(f\"분산 제거 후 descriptor shape: {descriptor_data_after_var.shape}\")\n",
    "\n",
    "    ## 상관관계 높은 descriptor 제거\n",
    "    descriptor_data_final, _ = remove_correlated_descriptors(descriptor_data_after_var, threshold=0.9)\n",
    "    print(f\"상관관계 제거 후 descriptor shape: {descriptor_data_final.shape}\")\n",
    "\n",
    "    # MD + Compound info\n",
    "    descriptor_data = pd.concat([compound_info, descriptor_data_final], axis=1)\n",
    "    print(f\"Descriptor 생성 후 데이터 shape (compound info 포함): {descriptor_data.shape}\")\n",
    "\n",
    "    # MD + Compound info + FP\n",
    "    fingerprints = descriptor_data['canonical_SMILES'].apply(lambda x: smiles_to_fingerprint(x))\n",
    "    fingerprints_array = np.vstack(fingerprints.values)\n",
    "    fp_df = pd.DataFrame(fingerprints_array, columns=[f'X{i+1}' for i in range(fingerprints_array.shape[1])])\n",
    "    final_data = pd.concat([descriptor_data, fp_df], axis=1)\n",
    "    print(f\"Fingerprint 추가 후 최종 데이터 shape: {final_data.shape}\")\n",
    "\n",
    "    return final_data\n",
    "\n",
    "def balance_dataset_by_source(df, scale, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    active_data = df[df['source'] == 'active'].copy()\n",
    "    n_active = len(active_data)\n",
    "    \n",
    "    assay_inactive_data = df[df['source'] == 'assay_inactive'].copy()\n",
    "    decoy_data = df[df['source'] == 'decoy'].copy()\n",
    "    \n",
    "    target_inactive_count = n_active * scale\n",
    "    selected_inactive = pd.DataFrame()\n",
    "    \n",
    "    if len(assay_inactive_data) >= target_inactive_count:\n",
    "        selected_inactive = assay_inactive_data.sample(n=target_inactive_count, random_state=random_seed)\n",
    "    else:\n",
    "        selected_inactive = assay_inactive_data.copy()\n",
    "        remaining = target_inactive_count - len(assay_inactive_data)\n",
    "        if len(decoy_data) >= remaining:\n",
    "            additional_decoy = decoy_data.sample(n=remaining, random_state=random_seed)\n",
    "            selected_inactive = pd.concat([selected_inactive, additional_decoy], ignore_index=True)\n",
    "        else:\n",
    "            selected_inactive = pd.concat([selected_inactive, decoy_data], ignore_index=True)\n",
    "            print(f\"inactive 데이터 부족! assay_inactive {len(assay_inactive_data)}개 + decoy {len(decoy_data)}개 = 총 {len(selected_inactive)}개\")\n",
    "\n",
    "    balanced_data = pd.concat([active_data, selected_inactive], ignore_index=True)\n",
    "    balanced_data = balanced_data.sample(frac=1, random_state=random_seed).reset_index(drop=True)  # 섞기\n",
    "    \n",
    "    print(f\"\\n데이터 균형 조정 (scale={scale}):\")\n",
    "    print(f\"Active: {len(active_data)}개\")\n",
    "    print(f\"Inactive: {len(selected_inactive)}개\") \n",
    "    print(f\"총: {len(balanced_data)}개\")\n",
    "    \n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b6b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "for data_name in [\"FTO_training_total\"]:\n",
    "    print(f\"\\n{'='*50}Processing dataset: {data_name}{'='*50}\")\n",
    "    for ignore3d in [True, False]:\n",
    "        # 원본 데이터 불러오기\n",
    "        input_path = f\"raw/FTO_training/{data_name}.csv\"\n",
    "        raw_data = pd.read_csv(input_path)\n",
    "\n",
    "        # MD, FP 생성\n",
    "        final_data = smiles_to_MD_FP(raw_data, ignore3d)\n",
    "\n",
    "        # 최종 데이터 저장\n",
    "        output_cleaned_path = f\"preprocessed/filtered_{data_name}_ignore3D_{ignore3d}.csv\"\n",
    "        final_data.to_csv(output_cleaned_path, index=False)\n",
    "\n",
    "        for scale in [1, 3, 5, 10, 20, 50]:\n",
    "            balanced_df = balance_dataset_by_source(final_data, scale, random_seed=42)\n",
    "            \n",
    "            output_path = f\"preprocessed/filtered_FTO_training_{scale}x_ignore3D_{ignore3d}.csv\"\n",
    "            balanced_df.to_csv(output_path, index=False)\n",
    "            print(f\"저장 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e540a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 화합물 수: 70413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:37:01] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "[08:37:01] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[08:37:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:37:02] Explicit valence for atom # 1 Cl, 4, is greater than permitted\n",
      "[08:37:03] Explicit valence for atom # 13 B, 4, is greater than permitted\n",
      "[08:37:05] Explicit valence for atom # 34 N, 4, is greater than permitted\n",
      "[08:37:05] Explicit valence for atom # 0 P, 11, is greater than permitted\n",
      "[08:37:09] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 분자 수: 70413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES:   4%|▍         | 2829/70413 [00:00<00:15, 4331.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES 1983: None, Error: No registered converter was able to produce a C++ rvalue of type class std::basic_string<wchar_t,struct std::char_traits<wchar_t>,class std::allocator<wchar_t> > from this Python object of type NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES:   8%|▊         | 5651/70413 [00:01<00:15, 4122.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES 5020: None, Error: No registered converter was able to produce a C++ rvalue of type class std::basic_string<wchar_t,struct std::char_traits<wchar_t>,class std::allocator<wchar_t> > from this Python object of type NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES:   9%|▉         | 6487/70413 [00:01<00:15, 4080.93it/s][08:37:39] WARNING: not removing hydrogen atom without neighbors\n",
      "Processing SMILES:  11%|█         | 7709/70413 [00:01<00:15, 3986.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES 7149: None, Error: No registered converter was able to produce a C++ rvalue of type class std::basic_string<wchar_t,struct std::char_traits<wchar_t>,class std::allocator<wchar_t> > from this Python object of type NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES:  14%|█▎        | 9681/70413 [00:02<00:16, 3706.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES 8974: None, Error: No registered converter was able to produce a C++ rvalue of type class std::basic_string<wchar_t,struct std::char_traits<wchar_t>,class std::allocator<wchar_t> > from this Python object of type NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES:  22%|██▏       | 15313/70413 [00:04<00:14, 3896.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES 14685: None, Error: No registered converter was able to produce a C++ rvalue of type class std::basic_string<wchar_t,struct std::char_traits<wchar_t>,class std::allocator<wchar_t> > from this Python object of type NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES:  24%|██▍       | 17223/70413 [00:04<00:17, 3041.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES 16619: None, Error: No registered converter was able to produce a C++ rvalue of type class std::basic_string<wchar_t,struct std::char_traits<wchar_t>,class std::allocator<wchar_t> > from this Python object of type NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES:  33%|███▎      | 22970/70413 [00:07<00:16, 2936.29it/s][08:37:45] WARNING: not removing hydrogen atom without neighbors\n",
      "Processing SMILES: 100%|██████████| 70413/70413 [00:31<00:00, 2268.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid molecules for descriptor calculation: 70407/70413\n",
      "Using 8/12 cores for descriptor calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/70407 [00:06<5:04:20,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 90/70407 [00:17<13:22:05,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 335/70407 [00:39<2:08:57,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 6733/70407 [10:05<1:08:04, 15.59it/s] [08:48:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:48:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:48:16] WARNING: not removing hydrogen atom without neighbors\n",
      " 31%|███       | 21529/70407 [46:11<3:26:41,  3.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mol\\lib\\site-packages\\mordred\\_matrix_attributes.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  s += (eig.vec[i, eig.max] * eig.vec[j, eig.max]) ** -0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 23257/70407 [49:25<2:15:26,  5.80it/s] [09:27:36] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:27:36] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:27:36] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|██████████| 70407/70407 [3:12:45<00:00,  6.09it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정제 전 데이터 shape: (72977, 1617)\n",
      "제거된 결측/비정상 값 포함 컬럼 수: 1033개\n",
      "결측 제거 후 descriptor shape: (72977, 580)\n",
      "제거된 낮은 분산 descriptor 수: 0개\n",
      "분산 제거 후 descriptor shape: (72977, 580)\n",
      "제거된 상관관계 높은 descriptor 수: 346개\n",
      "상관관계 제거 후 descriptor shape: (72977, 234)\n",
      "Descriptor 생성 후 데이터 shape (compound info 포함): (72977, 238)\n"
     ]
    }
   ],
   "source": [
    "# FooDB data\n",
    "foodb_json_file = \"foodb/foodb_2020_04_07_json/Compound.json\"\n",
    "compounds = []\n",
    "\n",
    "with open(foodb_json_file, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            try:\n",
    "                compound = json.loads(line)\n",
    "                smiles = compound.get('moldb_smiles')\n",
    "                name = compound.get('name')\n",
    "                compound_id = compound.get('public_id')\n",
    "                if smiles:\n",
    "                    compounds.append({\n",
    "                        'id': compound_id,\n",
    "                        'name': name,\n",
    "                        'raw_SMILES': smiles\n",
    "                    })\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "foodb_df = pd.DataFrame(compounds)\n",
    "print(f\"로드된 화합물 수: {len(foodb_df)}\")\n",
    "\n",
    "foodb_df['canonical_SMILES'] = foodb_df['raw_SMILES'].apply(to_canonical_smiles)\n",
    "\n",
    "smiles_list = foodb_df['canonical_SMILES'].tolist()\n",
    "print(\"총 분자 수:\", len(smiles_list))\n",
    "\n",
    "# MD\n",
    "desc_df = calc_descriptors(smiles_list, leave_cores=4, ignore3D=ignore3d)\n",
    "if 'canonical_SMILES' not in desc_df.columns:\n",
    "    desc_df.insert(0, 'canonical_SMILES', smiles_list)\n",
    "dataset = foodb_df.merge(desc_df, on='canonical_SMILES', how='left')\n",
    "\n",
    "compound_info = dataset.iloc[:, :4]\n",
    "descriptor_data = dataset.iloc[:, 4:]\n",
    "print(f\"정제 전 데이터 shape: {dataset.shape}\")\n",
    "\n",
    "# MD 전처리\n",
    "## 결측치 제거\n",
    "descriptor_data_cleaned, _ = remove_invalid_descriptors(descriptor_data)\n",
    "print(f\"결측 제거 후 descriptor shape: {descriptor_data_cleaned.shape}\")\n",
    "\n",
    "## 분산이 낮은 descriptor 제거\n",
    "descriptor_data_after_var, _ = remove_low_variance_descriptors(descriptor_data_cleaned, threshold=1e-6)\n",
    "print(f\"분산 제거 후 descriptor shape: {descriptor_data_after_var.shape}\")\n",
    "\n",
    "## 상관관계 높은 descriptor 제거\n",
    "descriptor_data_final, _ = remove_correlated_descriptors(descriptor_data_after_var, threshold=0.9)\n",
    "print(f\"상관관계 제거 후 descriptor shape: {descriptor_data_final.shape}\")\n",
    "\n",
    "# MD + Compound info\n",
    "descriptor_data = pd.concat([compound_info, descriptor_data_final], axis=1)\n",
    "print(f\"Descriptor 생성 후 데이터 shape (compound info 포함): {descriptor_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573dda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_data = descriptor_data.dropna(subset=['canonical_SMILES']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d18633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:29:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:29:39] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint 추가 후 최종 데이터 shape: (72971, 1262)\n"
     ]
    }
   ],
   "source": [
    "# MD + Compound info + FP\n",
    "fingerprints = descriptor_data['canonical_SMILES'].apply(lambda x: smiles_to_fingerprint(x))\n",
    "fingerprints_array = np.vstack(fingerprints.values)\n",
    "fp_df = pd.DataFrame(fingerprints_array, columns=[f'X{i+1}' for i in range(fingerprints_array.shape[1])])\n",
    "final_data = pd.concat([descriptor_data, fp_df], axis=1)\n",
    "print(f\"Fingerprint 추가 후 최종 데이터 shape: {final_data.shape}\")\n",
    "\n",
    "output_cleaned_path = \"foodb/filtered_foodb.csv\"\n",
    "final_data.to_csv(output_cleaned_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
